{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use this if you want to use and initialize sprak, sparkcontext\n",
    "'''import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark import SparkConf,SparkContext\n",
    "'''\n",
    "import thunder as td\n",
    "from extraction import NMF\n",
    "from os import listdir\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set spark config accoring to your loacl machine [master and memory]\n",
    "#conf = SparkConf().setAppName(\"neuronSegmentation\")\n",
    "#conf = (conf.setMaster('local[*]')\n",
    "#        .set('spark.executor.memory', '4G')\n",
    "#        .set('spark.driver.memory', '10G'))\n",
    "#sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating list of thunder image Vectors of all dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA READ!\n"
     ]
    }
   ],
   "source": [
    "#the path of data is hard-code for now. \n",
    "#when running as python file , we can take it as an input argument\n",
    "data = td.images.fromtif(path='/home/hiten/Desktop/neurofinder.00.00/images',ext=\"tiff\")\n",
    "print(\"DATA READ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use engine=sc as formatted below to use spark while reading th data\n",
    "#data = td.images.fromtif(path='/home/hiten/Desktop/neurofinder.00.00/images',engine=sc,ext=\"tiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating NMF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the model and play with various values of k,percentile to get efficient results\n",
    "algorithm = NMF(k=10, max_iter=20, percentile=95, overlap=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting models for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit our data in the model\n",
    "model = algorithm.fit(data, chunk_size=(50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixing overlapping pixels\n",
    "merged = model.merge(overlap=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving cordinates value in a list and passing it to jsonString\n",
    "coordinates = [{'coordinates': x.coordinates.tolist()} for x in merged.regions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonString = {'dataset': \"00.00.test\", 'regions': coordinates}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving the desired format output to submit on AutoLAB\n",
    "with open('output' + \"00.00.test\" +'.json', 'w') as f:\n",
    "    f.write(json.dumps(jsonString))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
